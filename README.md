# ğŸ§  Simple XOR Neural Network  

## ğŸ‘¨â€ğŸ’» About the Creator  
This project was developed by **Jumayna AbdelHay Ghida**, an **AI student at Delta University**, **Student ID: [4221107]**.

## ğŸ“Œ Project Overview  
This project implements a **simple neural network** in Python to solve the **XOR problem**, a fundamental task in neural networks. The network is built **from scratch** without using deep learning libraries like TensorFlow or PyTorch.  

## ğŸ“Œ Why is this Code Important?  
The XOR problem is a classic example demonstrating the necessity of **non-linearity** in neural networks. A single-layer perceptron cannot solve XOR because it is not linearly separable. This project implements a **basic feedforward neural network with one hidden layer**, trained using **backpropagation** and **gradient descent**.  

## ğŸ”¹ Key Features  
âœ… **Fully custom neural network** (no external frameworks).  
âœ… **Backpropagation and gradient descent** for learning.  
âœ… **Sigmoid activation function** for non-linearity.  
âœ… **Basic implementation of a multi-layer perceptron (MLP).**  

## ğŸš€ How to Run the Code  

1ï¸âƒ£ Clone this repository:  
```bash
git clone https://github.com/JumaynaGhida/XOR-Neural-Net.git
cd XOR-Neural-Net
